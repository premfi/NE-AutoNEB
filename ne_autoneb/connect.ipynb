{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not strictly necessary, but useful in the notebook\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# set visible cuda devices.\n",
    "# first visible device will be set as default. Separate multiple devices by comma: ...=0,1,2\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports to nicely render progress bars in the notebook\n",
    "import tqdm\n",
    "from tqdm.auto import tqdm as autotqdm\n",
    "tqdm.tqdm = autotqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyKeOps with torch bindings is working!\n"
     ]
    }
   ],
   "source": [
    "import losses # should print \"pyKeOps with torch bindings is working!\", otherwise PyKeOps is not functioning properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import UMAP_loss, TSNE_loss\n",
    "from autoneb import autoneb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any dataset can be used, it does not need to be from torchvision.datasets\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "fashionmnist = datasets.FashionMNIST(\n",
    "    root=\"datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "x_data = fashionmnist.data[:500]    # load your preferred dataset here, x values\n",
    "x_data = torch.flatten(x_data, start_dim=1) # x_data needs to be (N, 1)-dimensional\n",
    "\n",
    "y_data = fashionmnist.targets[:500] # load your preferred dataset here, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Embedding generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is not necessary for running this test notebook, as example embeddings have already been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate UMAP embeddings which can later be connected\n",
    "import umap\n",
    "num_minima = 3\n",
    "\n",
    "umap_embs = []\n",
    "for i in tqdm.tqdm(range(num_minima), \"Find UMAP minimum\"):\n",
    "    reducer = umap.UMAP(a=1.0, b=1.0, init=\"random\")\n",
    "    umap_embs = umap_embs + [reducer.fit_transform(x_data)]\n",
    "\n",
    "np.save(\"embeddings/UMAP_Fashion\", np.array(umap_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate t-SNE embeddings which can later be connected\n",
    "from openTSNE import TSNE\n",
    "num_minima = 3\n",
    "TSNE_params = {\"initialization\": \"random\",\n",
    "               \"n_jobs\": 1,\n",
    "               \"verbose\": True}\n",
    "\n",
    "tsne_embs = []\n",
    "for i in tqdm.tqdm(range(num_minima), \"Find t-SNE minimum\"):\n",
    "    tsne = TSNE(**TSNE_params)\n",
    "    tsne_embs = tsne_embs + [tsne.fit(x_data)]\n",
    "\n",
    "np.save(\"embeddings/TSNE_Fashion\", np.array(tsne_embs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss directly depends on the original high-dimensional data. Loss functions are thus implemented as objects, processing the dataset during initialization. They can only be used on the dataset they were initialized on, but several instances of the same loss class, initialized on different datasets, can exist simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP_loss initialized successfully\n",
      "TSNE_loss initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# several instances of the UMAP_precomputed_loss class with different parameters can exist simultaneously\n",
    "fashion_UMAP_loss = UMAP_loss(x_data, y_data) # takes some time when using the whole dataset, as\n",
    "                                              # one example umap embedding needs to be optimized\n",
    "\n",
    "# several instances of the TSNE_precomputed_loss class with different parameters can exist simultaneously\n",
    "fashion_TSNE_loss = TSNE_loss(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoNEB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 500, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_embs = np.load(\"embeddings/TSNE_Fashion.npy\")\n",
    "tsne_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 500, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_embs = np.load(\"embeddings/UMAP_Fashion.npy\")\n",
    "umap_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect two minima on the UMAP or TSNE loss surface, optionally with a predefined initial path.\n",
      "        nodes : np.ndarray or torch.Tensor or list of np.ndarrays or torch.Tensors\n",
      "            Embeddings; data points from x_data that are to be connected.\n",
      "        loss_inst : Instance of one of the classes in \"losses.py\"\n",
      "            Object containing the precalculated high-dimensional similarities of a specific\n",
      "            dataset, which is passed as parameter during its initialization.\n",
      "        config_path : str\n",
      "            Path to the config file to be used for optimization during graph creation and autoneb.\n",
      "        initialize : int or np.ndarray or torch.Tensor, default=3\n",
      "            If int, path will be initialized by interpolating with this number of points.\n",
      "            Alternatively, an arbitrary initial path can be passed, consisting of an\n",
      "            arbitrary number of embeddings, excluding the node embeddings themselves.\n",
      "            Path needs to be of shape (num_pivots, num_datapoints, 2).\n",
      "        graph_name : str, default=\"unnamed_graph\"\n",
      "            File name for the finished graph. Will be saved in folder as graphs/graph_name.pickle.\n",
      "        node_idxs : list of int, optional\n",
      "            Custom indexes for the nodes of the graph. Default is ascending numbers starting at 1.\n",
      "        align : bool, default=True\n",
      "            If set True, embeddings will be centered and a procrustes analysis performed, that\n",
      "            rotates and reflects them for maximum overlap with the first embedding. Embeddings are\n",
      "            temporarily rescaled during procrustes, but are rescaled to their original size after.\n",
      "            Alignment happens after pre-optimization of each embedding.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(autoneb.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run autoneb, connecting two embeddings. Use suitable loss instance\n",
    "# to use a predefined path as initialization, use \"initialize\" argument with np.ndarray or torch.Tensor\n",
    "autoneb(umap_embs, loss_inst=fashion_UMAP_loss, config_path=\"configs/example_config.yaml\", initialize=3, graph_name=\"umap_example\", node_idxs=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warning ```Minima 1 and 2 are missing intermediate cycles set().``` always arises and can be ignored. It stems from the changed initialization procedure which makes torch_autoneb believe there should already exist a proper optimized connection instead of just the initial path."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
